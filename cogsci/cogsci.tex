% Template for Cogsci submission with R Markdown

% Stuff changed from original Markdown PLOS Template
\documentclass[10pt, letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{float}
\usepackage{caption}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}

% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% hyperref package, useful for hyperlinks
\usepackage{hyperref}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

% Sweave(-like)
\usepackage{fancyvrb}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{}
\DefineVerbatimEnvironment{Code}{Verbatim}{}
\DefineVerbatimEnvironment{CodeInput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{CodeOutput}{Verbatim}{}
\newenvironment{CodeChunk}{}{}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color}

% Use doublespacing - comment out for single spacing
%\usepackage{setspace}
%\doublespacing


% % Text layout
% \topmargin 0.0cm
% \oddsidemargin 0.5cm
% \evensidemargin 0.5cm
% \textwidth 16cm
% \textheight 21cm

\title{Word Learning as Network Growth: A Cross-linguistic Analysis}

\usepackage[subtle]{savetrees}

\author{{\large \bf Abdellah Fourtassi} \\ \texttt{afourtas@stanford.edu} \\ Department of Psychology \\ Stanford University \And {\large \bf Yuan Bian} \\ \texttt{ybian.uiuc@gmail.com} \\ Department of Psychology \\ University of Illinois \And {\large \bf Michael C. Frank} \\ \texttt{mcfrank@stanford.edu} \\ Department of Psychology \\ Stanford University}

\begin{document}

\maketitle

\begin{abstract}
Children tend to produce words earlier when they are connected to other
words along both the phonological and semantic dimensions. Though this
connectivity effect has been extensively documented, little is known
about the underlying developmental mechanism. One view suggests that
learning is primarily driven by a network growth model where highly
connected words in the child's ealy lexicon attract similar words.
Another view suggests that learning is driven, not by highly connected
words in the early internal lexicon, but by words that are highly
connected in the external learning environment. The present study tests
both scenarios systematically in both the phonological and the semantic
domains, and across 8 languages. We show that external connectivity in
the learning environment drives growth in both the semantic and the
phonological networks, and that this pattern is consistent
cross-linguistically. The findings suggest a word learning mechanism
where children harness their statistical learning abilities to
(indirectly) detect and learn highly connected words in the learning
environment.

\textbf{Keywords:}
semantic network, phonological network, network growth, mechanism of
word learning
\end{abstract}

\section{Introduction}\label{introduction}

What factors shape vocabulary learning over the course of early
childhood? To investigate this question, scientists have adopted
multiple research strategies, from conducting controlled laboratory
experiments (e.g. Markman, 1990) to analysing dense corpora capturing
language learning in context (e.g., B. C. Roy, Frank, DeCamp, Miller, \&
Roy, 2015). One strategy consists in documenting the timeline of words'
acquisition, and studying the properties that make words easy or hard to
learn. For example, within a lexical category, words that are more
frequent in child-directed speech are acquired earlier (J. C. Goodman,
Dale, \& Li, 2008). Other factors include word length, the mean length
of utterances in which the word occurs, and concreteness (see Braginsky,
Yurovsky, Marchman, \& Frank, 2016).

Besides these word-level properties, the lexical structure (that is, how
words relate to each other) also influences the age of acquisition of
words. The lexical structure is best characterized in terms of a network
where each node represents a word in the vocabulary, and each link
between two nodes represents a relationship between the corresponding
pair of words. Previous studies investigated early vocabulary networks
based on different word relations such as shared semantic features,
target-cue relationships in free association norms, co-occurrence in
child directed speech, and phonological similarity. These studies have
found that children tend to produce earlier the words that have higher
neighborhood density (i.e., high connectivity in the network) both at
the phonological and the semantic level (Beckage, Smith, \& Hills, 2011;
Engelthaler \& Hills, 2017; Hills, Maouene, Riordan, \& Smith, 2010;
Hills, Maouene, Maouene, Sheya, \& Smith, 2009; Stella, Beckage, \&
Brede, 2017; Stokes, 2010; Storkel, 2009).

While most studies focused on the static properties of the lexical
network, a few have investigated the underlying developmental process.
Steyvers \& Tenenbaum (2005) suggested that the effect of connectivity
is the consequence of how the lexical network gets constructed in the
child's mind. According to this explanation, known as Preferential
Attachment (PAT), highly connected words in the child's lexicon tend to
``attract'' more words over time, in a rich-get-richer scenario
(Barabasi \& Albert, 1999). In other words, what predicts word learning
is the \emph{internal} connectivity in the child's early lexicon. In
contrast, Hills et al. (2009) suggested that what biases the learning is
not the connectivity in the child's internal lexicon but, rather,
\emph{external} connectivity in the learning environment. They called
this alternative explanation Preferential Acquisition (PAC). Figure
\ref{fig:growth} shows an illustration of both growth scenarios with the
same simplified network. These two proposals represent two divergent
ideas about the role of lexical networks in acquisition. On the PAT
proposal, network structure is a causal factor in early word learning;
in contrast, on the PAC approach, network structure is not internally
represented and, therefore, might be an epiphenomenon of the statistics
of the linguisitc input (see discussion).

\begin{CodeChunk}
\begin{figure}[H]

{\centering \includegraphics{figs/growth-1} 

}

\caption{\label{fig:growth}Filled circles (I1-I4) represent known words (internal lexicon), and empty circles (E1 and E2) represent words that have not been learned yet (external lexicon). Black lines represent links that are relevant in each growth scenario, and gray lines represent links that are irrelevant. For PAT, each candidate node is characterized with the average degree (i.e., number of links) of the existing nodes that it would attach to. Thus, according to PAT, the node E1 is more likely to enter the lexicon first. For PAC, each candidate node is characterized with its degree in the entire network. According th PAC, the node E2 is more likely to enter the lexicon first.}\label{fig:growth}
\end{figure}
\end{CodeChunk}

Studies that investigate lexical network growth have focused on semantic
networks using English data (Hills et al., 2010, 2009; Steyvers \&
Tenenbaum, 2005). The novelty of the current study is that it
investigates whether phonological networks, like semantic networks, grow
by PAC, or if they rather grow by PAT. It also provides a systematic
comparison of both network growth scenarios in the phonological and the
semantic domains and assesses their relative contribution to the
learning process. Moreover, it tests the generality of the findings
across eight languages.

\begin{CodeChunk}
\begin{figure*}[h]

{\centering \includegraphics{figs/all_data-1} 

}

\caption{\label{fig:data_all}Age of acquisition in the global network as predicted by the degree in this network. Results are shown in each language for the phonological network (top) and the semantic network (bottom). Each point is a word, with lines indicating linear model fits.}\label{fig:all_data}
\end{figure*}
\end{CodeChunk}

\begin{CodeChunk}
\begin{figure*}[h]

{\centering \includegraphics{figs/degree_distribution-1} 

}

\caption{\label{fig:degree_distribution}Log-log plot of the cumulative degree distribution function for the global phonological and semantic networks across languages. A perfect power law distribution should appear as a straight line in this graph.}\label{fig:degree_distribution}
\end{figure*}
\end{CodeChunk}

\section{Networks}\label{networks}

\subsection{Data}\label{data}

We used data from Wordbank (Frank, Braginsky, Yurovsky, \& Marchman,
2017), an open repository aggregating cross-linguistic language
developmental data of the MacArthur-Bates Communicative Development
Inventory (CDI), a parent report vocabulary checklist. Parent report is
a reliable and valid measure of children's vocabulary that allows for
the cost-effective collection of datasets large enough to test
network-based models of acquisition (Fenson et al., 1994). We used the
\emph{Words and Sentence} version of the CDI which contains the
productive vocabulary of toddlers (age varied between 16 to 36 months).
Following previous studies (Hills et al., 2009; e.g., Storkel, 2009), we
restricted our analysis to the category of nouns. The age of acquisition
was defined by the month at which a word was produced by at least 50\%
of children (J. C. Goodman et al., 2008).

We obtained these nouns in eight languages: Croatian, Danish, English,
Italian, Norwegian, Russian, Spanish, and Turkish. We used the subset of
nouns that had entries in the Florida Association Norms (see below).
Since these norms are available only in English, we used the
hand-checked translation equivalents provided by Braginsky by Braginsky
et al. (2016), allowing us to use the English association norms across
languages. Table \ref{tab:stats} gives an overview of the data used.
Translation equivalents were originally constructed for a subset of
words appearing on the toddler CDI form (the subset is labeled
\emph{Words and Gestures}), and so not all words are currently
available. Note, however, that all languages have at least 60\% of nouns
translated.

\begin{table}[H]
\centering
\begin{tabular}{rlrrr}
  \hline
 & language & total & translated & normed \\ 
  \hline
1 & Croatian & 253 & 177 & 170 \\ 
  2 & Danish & 295 & 198 & 187 \\ 
  3 & English & 296 & 296 & 274 \\ 
  4 & Italian & 311 & 203 & 194 \\ 
  5 & Norwegian & 305 & 193 & 186 \\ 
  6 & Russian & 311 & 311 & 285 \\ 
  7 & Spanish & 240 & 173 & 163 \\ 
  8 & Turkish & 293 & 175 & 164 \\ 
   \hline
\end{tabular}
\caption{\label{tab:stats}Total number of nouns produced by toddlers in the CDI (left). We included in our study the subset of these nouns that had available English translations (middle). The final set consisted of nouns that had both available translations as well entries in the Free Association Norms (right).} 
\end{table}

\subsection{Semantic networks}\label{semantic-networks}

Hills et al. (2009), we used as an index of semantic relatedness the
Florida Free Association Norms (Nelson, McEvoy, \& Schreiber, 1998).
This dataset was collected by giving adult participants a word (the
cue), and asking them to write the first word that comes to mind (the
target). For example, when given the word ``ball'', they might answer
with the word ``game''. A pair of nodes were connected by a directed
link from the cue to the target if there was a cue-target relationship
between these nodes in the association norms. Each node was
characterized by its ``indegree'', which represents the number of links
for which the word was the target. To model growth from month to month,
we constructed a different network at each month, made of words that
have been learned at that month.

\subsection{Phonological networks}\label{phonological-networks}

We generated approximate International Phonetic Alphabet (IPA)
transcriptions from the orthographic transcription, across languages,
using the open source text-to-speech software
\textbf{\href{http://http://espeak.sourceforge.net/}{Espeak}.} We used
the Levenshtein (edit) distance as a measure of phonological relatedness
between two nodes. The measure counts the minimum number of operations
(insertions, deletions, substitutions) required to change one string
into another.

In previous studies, two nodes were linked if they had an edit distance
of 1 (Stokes, 2010; Storkel, 2009). However, in these previous studies
the network was built using an adult vocabulary. However, since the
children's vocabulary contains very few word pairs with an edit distance
of 1, the resulting networks were too sparse and uninformative. Thus, we
increased the threshold from 1 to 2, that is, two nodes were related if
their edit distance was equal to 1 or 2. Each node was characterized
with its degree, i.e., the number of links it shares with other words.

\section{Analysis}\label{analysis}

\subsection{Static properties of the global
network}\label{static-properties-of-the-global-network}

We start by analysing word connectivity in the global (static) network.
We constructed this network using nouns at the oldest age for which we
have CDI data (e.g., in English this corresponds to the network by 30
months). This global netowrk is the end-state towards which both PAT and
PAC should converge by the last month of learning. Morover, following
Hills et al. (2009), we used this end-state netowrk as a proxy for the
external connectivity in the learning environment. Below we analyse
properties of this global networks that are relevant to PAT and/or PAC.

\subsubsection{Connectivity predicts the age of
acquisition}\label{connectivity-predicts-the-age-of-acquisition}

Connectivity in the global network is directly related to PAC as it
represents the explicit criterion PAC uses to determine what words
should be learned first (Figure \ref{fig:growth}). Therefore, a direct
consequence of a PAC-like growth scenario is a correlation betweeen
connectivity in the global network and the age of
acquisition.\footnote{Note that this correlation is also compatible with PAT, even if this growth scenario does not rely explicity on external connectivity. Indeed, from a PAT perspective, higher connectivity in the global network is caused by earlier learning, i.e., some words end up being highly connected in the global network precisely because they happen to be acquired earlier (and therefore have a higher chance of forming more links over time).}
Figure \ref{fig:data_all} shows how the age of acquisition for each word
varies as a function of its connectivity/degree (or indegree for the
semantic network). For ease of visual comparison, the predictor (i.e.,
the degree) was centered and scaled across languages. The plots show,
overall, a negative correlation between the month of acquisition and the
degree, indicating that nouns with higher degrees are generally learned
earlier.

\subsubsection{Power law degree
distribution?}\label{power-law-degree-distribution}

We also analysed the global network's degree distribution. This property
is particularly relevant to PAT as this growth scenario is known to
generate networks with a power-law degree distribution (Barabasi \&
Albert, 1999). If the network displays this property, this fact would
strongly suggests a PAT-like generative process. Conversely, if the
degree distribution does not follow a power law, this fact would weaken
the case for PAT. The results are shown in Figure
\ref{fig:degree_distribution}. Overall, we did not find consistent
evidence for a power law distribution: the extent to which the degree
distribution approximates a power law varies across dimensions and
languages.

For a more direct test of the developmental process, we fit explicit
growth models to the data (next section).

\begin{CodeChunk}
\begin{figure*}[h]

{\centering \includegraphics{figs/pred_ind_img-1} 

}

\caption{\label{fig:pred_ind}Evaluation of network growth scenarios both individually (dotted), and when combined in the same growth model (solid). Each dot represents the mean of the posterior distribution of the corresponding growth parameter, with ranges representing 95\% credible intervals (computed using the highest density intervals).}\label{fig:pred_ind_img}
\end{figure*}
\end{CodeChunk}

\subsection{Network growth models}\label{network-growth-models}

\subsubsection{How does each growth scenario predict noun
development?}\label{how-does-each-growth-scenario-predict-noun-development}

To test the network growth scenarios, we fit different growth models to
the data. We proceeded as follows. We calculated the probability that a
word \(w_i\), with a growth value \(d_i\) would enter the lexicon at a
given month, using a softmax function:

\begin{equation}
 p(w_i)= \frac{e^{\beta d_i}}{\sum_j e^{\beta d_j} }
\end{equation}

\noindent where \(\beta\) is a fitted parameter that captures the
magnitude of the relationship between network parameters and growth
(analogous to a regression coefficient). A positive value of \(\beta\)
means that words with higher growth values \(d_i\) are acquired first,
and a negative value means that words with lower growth values are
acquired first (see Figure \ref{fig:growth} for illustrations of growth
scenarios, and how a word's growth value \(d_i\) is defined in each of
these scenarios). The normalization includes all words that could be
learned at that month.

We estimated the parameter \(\beta\) using a Bayesian approach. The
inference was performed using the probabilistic programming language
WebPPL (N. Goodman \& Stuhlmüller, 2014). We defined a uniform prior
over \(\beta\), and at each month, we computed the likelihood function
over words that could possibly enter the lexicon at that month, fit to
the words that have been actually learned at that month (using formula
1). Markov chain monte carlo sampling resulted in a posterior
distribution over \(\beta\), which we summarized in Figure
\ref{fig:pred_ind}.

Besides fitting a growth model to the data, we conducted another
evaluation. This second evaluation consists in determining, in each
month, the growth value distribution of all words that could possibly be
learned at this month, and then computing the z-score of each learned
word with respect to this distribution. For each growth scenario, we
tested if the distribution constituted by the z-scores of all learned
words was different from zero, using a one-sample t-test.

The results from both evaluations were very similar and lead essentially
to the same
conclusions.\footnote{we do not show here the results of the second evaluation because they were redundant with the results of the first evaluation}
For the semantic networks, the results replicate Hills et al.'s finding
in English, which was that the semantic network grows by PAC, not by
PAT. Moreover, this finding held in seven of the eight languages we
examined. The PAC model also fit better than PAT for phonological
networks. We note however that PAT, though weaker, fares better for the
phonological networks (where it predicts part of the growth process in
some languages such as Croatian, English, Norwegian and Russian) than it
does for the semantic networks (where it is rather universally
unpredictive).

\subsubsection{What is the relative contribution of each growth
model?}\label{what-is-the-relative-contribution-of-each-growth-model}

Above we evaluated the network growth scenarios individually. As a next
step, we analysed their relative contribution to the learning process.
This was done through adding more fitting parameters to the model, that
is, by substituting \(\beta d_i\) in formula (1) with:
\[\beta_{1} d_{i, 1} + \beta_{2} d_{i, 2} + \beta_{3} d_{i, 3} + \beta_{4} d_{i, 4}\]
where the indices represent the 4 networks: semPAT, semPAC, phonoPAT and
PhonoPAC. Using the same fitting technique, we obtained the values shown
in Figure \ref{fig:pred_ind}. PAC dominates the learning. Both
phonological and semantic networks contribute to lexical growth, but the
phonological network appears to be stronger and more consistent across
languages. In summary, the findings show that both semantic and
phonological networks contribute to the learning process, and that they
both grow primarily by PAC, relying on the external connectivity in the
learning environment, rather than the internal connectivity in the
acquired lexicon.

\begin{CodeChunk}
\begin{figure*}[h]

{\centering \includegraphics{figs/regressions_img-1} 

}

\caption{\label{fig:regressions_img}Estimates of predictor coefficients by language. Values above 0 indicate a positive relationship (e.g. longer words tend to have a higher AoA), while values below 0 indicate a negative relationship (e.g. words with higher frequency tend to have a lower AoA). Ranges indicate 95\% confidence intervals.}\label{fig:regressions_img}
\end{figure*}
\end{CodeChunk}

\subsection{Comparison to other known predictors of age of
acquisition}\label{comparison-to-other-known-predictors-of-age-of-acquisition}

We saw that the way semantic and phonological information is structured
in the learning environment (i.e., PAC) contribute to noun learning
across languages. However, we know that other factors influence learning
as well (e.g., Braginsky et al., 2016). Next we investigated how
semantic and phonological connectivity interact with two other factors.
The first one is word frequency, a well studied factor shown to predict
the age of acquisition in a reliable fashion (e.g. J. C. Goodman et al.,
2008). The second factor is word length, which correlates with
phonological connectivity.

Since PAT was uninformative, we dropped it from this analysis. Thus, we
no longer needed to fit the growth model month-by-month as in the
previous section. In fact, word utilities (i.e., growth values) in the
case of PAC are fixed, they do not depend on previously learned words. A
more direct way to assess and compare the contribution of PAC in
relation to other word-level factors is through conducting linear
regressions, where connectivity in the learning environment (at both the
phonological and semantic level), frequency and length predict the age
of acquisition.

We used the frequency estimates from Braginsky et al. (2016) where
unigram counts were derived based on CHILDES corpora in each language
(note that these frequency counts are based on transcripts from
independent sets of children and represent a general estimate of
environmental frequency across children). For each word, counts included
words that shared the same stem (e.g., cats counts as cat), or words
that were synonymous (e.g.~father counts as daddy). For word length, we
used our generated IPA transcription.

We conducted two analyses. We fit a linear regression for each language,
and we fit a linear mixed-effect to all the data pooled across
languages, with language as a random effect. Figure
\ref{fig:regressions_img} shows the coefficient estimate for each
predictor in each language, and Figure \ref{fig:regressions_all_img}
shows the coefficient estimates for all languages combined (all
predictors were centered and scaled). The findings were as follows.
Overall, frequency is the largest and most consistent predictor of age
of acquisition, replicating results for nouns across a variety of
analyses (Braginsky et al., 2016; J. C. Goodman et al., 2008; B. C. Roy
et al., 2015). Word length predicts learning in some languages such as
Croatian and Norwegian, but not in others (including English). It
remains, however, a significant predictor in the global model. As for
the factors of interest, i.e., semantic and phonological connectivity,
we also found cross-linguistic differences. The phonological
connectivity contributes to learning in languages such as Croatian,
English and Russian, whereas semantic connectivity contributes to
learning in Turkish, Spanish and to some extent in Croatian, but
interestingly not in
English.\footnote{Semantic connectivity does not explain variance in English data beyond that explained by phonological connectivity, frequency and length. This contrasts with the original finding in Hills et al. 2009. However, in this previous study, semantic connectivity was not tested in a model that included frequency, length and phonological connectivity as covariates. Another important difference is the number of words tested: our study uses a larger set of nouns.}
Despite this cross-linguistic variation, both phonological and semantic
connectivity remain significant predictors in the global model.

\section{Discussion}\label{discussion}

The present study provided a comprehensive analysis of how lexical
connectivity influences the age of acquisition of nouns in toddlers. We
compared two network growth scenarios and assessed their relative
contributions and the relative contributions of phonological
vs.~semantic networks across eight languages. One scenario, PAT,
described a ``rich get richer'' network growth model in which the
structure of the learner's internal network determines future growth;
the other, PAC, described a model in which the external, global
environmental network structure determines learners' growth patterns.
Part of the findings largely replicate the results obtained in Hills et
al. (2009), i.e., semantic networks (based on free associations) grow by
preferential acquisition, not by preferential attachment. Another
finding was that phonological networks also grow primarily by
preferential acquisition, especially when both scenarios (PAT and PAC)
were pitted against each other in the same model. These findings
generalize well across languages. Moreover, both semantic and
phonological connectivity in the learning environment (i.e., PAC)
predict growth in a consistent way across many languages. However, when
pitted against other known predictors of age of acquisition (word
frequency and length), the effect of word connectivity shows a
cross-linguistic variation, predicting learning in some languages, but
not in others. Despite this cross-linguistic variation, both
phonological and semantic connectivity contribute to the overall
learning (when data is pooled across languages).

\begin{CodeChunk}
\begin{figure}[H]

{\centering \includegraphics{figs/regressions_all_img-1} 

}

\caption{\label{fig:regressions_all_img}Estimates of predictor coefficients in the combined mixed-effect model with language as a random effect. Ranges indicate 95\% confidence intervals. Lighter points indicate estimates of PAC predictors in a model that does not include frequency and length as covariates.}\label{fig:regressions_all_img}
\end{figure}
\end{CodeChunk}

One important result of the study is that children start by learning
words that have high phonological and semantic similarity with a variety
of other words in the learning environment, not in the child's available
lexicon. This suggests that children are sensitive to connectivity even
without having first acquired the connected words. How can children
indirectly detect highly connected words, and why would such words be
more readily learned?

In the semantic case, free association can be predicted through the
patterns of word co-occurrence (Griffiths, Steyvers, \& Tenenbaum,
2007), meaning that highly connected words tend to be the words that
co-occur with many other words in various contexts. One possibility,
suggested by Hills et al. (2010), is that the referents of such words
are more easily disambiguated from other potential referents (because
their presence in mulitiple contexts provides more diambiguating
statisitcs about their true referents). (Smith \& Yu, 2008) showed that
children can disambiguate the words' referents based on such
cross-situational statisitics (Smith \& Yu, 2008).

In the phonological case, connectivity is inherently correlated with
phonotactic probability (Vitevitch, Luce, Pisoni, \& Auer, 1999). That
is, highly connected words tend to be made of frequent sound sequences.
Even infants (whose vocabulary is still very rudimentary) show a
sensitivity for high frequency sound sequences in the ambient language
(Jusczyk, Luce, \& Charles-Luce, 1994). Moreover, it was shown that
phonotactic probability facilitates learning and recognition of novel
words in toddlers and preschoolers (MacRoy-Higgins, Shafer, Schwartz, \&
Marton, 2014; Storkel, 2001). In other words, children's sensitivity to
local phonotactic regularities might lead them to learn
higher-probability words more easily. This learning effect in turn would
lead to an observed pattern of growth that would appear to follow the
PAC growth model even though learners themselves would only be tracking
local statistics.

Finally, while validating previous results using network growth models,
our study suggests that these correlational patterns may emerge from the
operation of simpler mechanisms. One question for future experimental
work is whether such patterns of growth can be produced in controlled
behavioral experiments.

\vspace{1em}

\fbox{\parbox[b][][c]{7.3cm}{\centering All data and code for these analyses are available at\ \url{https://github.com/afourtassi/networks}}}
\vspace{1em}

\section{Acknowledgements}\label{acknowledgements}

This work was supported by a post-doctoral grant from the Fyssen
Foundation.

\section{References}\label{references}

\setlength{\parindent}{-0.1in} \setlength{\leftskip}{0.125in} \noindent

\hypertarget{refs}{}
\hypertarget{ref-barabasi99}{}
Barabasi, A.-L., \& Albert, R. (1999). Emergence of scaling in random
networks. \emph{Science}, \emph{286}(5439), 509--512.

\hypertarget{ref-beckage2011}{}
Beckage, N. M., Smith, L., \& Hills, T. T. (2011). Small worlds and
semantic network growth in typical and late talkers. \emph{PLOS ONE},
\emph{6}(5), 1--6.

\hypertarget{ref-braginsky2016}{}
Braginsky, M., Yurovsky, D., Marchman, V. A., \& Frank, M. C. (2016).
From uh-oh to tomorrow: Predicting age of acquisition for early words
across languages. In \emph{Proceedings of the 38th Annual Conference of
the Cognitive Science Society}.

\hypertarget{ref-engelthaler2017}{}
Engelthaler, T., \& Hills, T. T. (2017). Feature biases in early word
learning: Network distinctiveness predicts age of acquisition.
\emph{Cognitive Science}, \emph{41}, 120--140.

\hypertarget{ref-fenson94}{}
Fenson, L., Dale, P. S., Reznick, J. S., Bates, E., Thal, D. J.,
Pethick, S. J., \ldots{} Stiles, J. (1994). Variability in early
communicative development. \emph{Monographs of the Society for Research
in Child Development}, \emph{59}(5), i--185.

\hypertarget{ref-frank2017}{}
Frank, M. C., Braginsky, M., Yurovsky, D., \& Marchman, V. A. (2017).
Wordbank: An open repository for developmental vocabulary data.
\emph{Journal of Child Language}, \emph{44}(3), 677--694.

\hypertarget{ref-goodman2008}{}
Goodman, J. C., Dale, P. S., \& Li, P. (2008). Does frequency count?
Parental input and the acquisition of vocabulary. \emph{Journal of Child
Language}, \emph{35}(3), 515--531.

\hypertarget{ref-dippl}{}
Goodman, N., \& Stuhlmüller, A. (2014). The Design and Implementation of
Probabilistic Programming Languages. \url{http://dippl.org}.

\hypertarget{ref-griffiths07}{}
Griffiths, T. L., Steyvers, M., \& Tenenbaum, J. B. (2007). Topics in
semantic representation. \emph{Psychological Review}, \emph{114}(2),
2007.

\hypertarget{ref-hills2010}{}
Hills, T. T., Maouene, J., Riordan, B., \& Smith, L. B. (2010). The
associative structure of language: Contextual diversity in early word
learning. \emph{Journal of Memory and Language}, \emph{63}(3), 259--273.

\hypertarget{ref-hills2009}{}
Hills, T. T., Maouene, M., Maouene, J., Sheya, A., \& Smith, L. (2009).
Longitudinal analysis of early semantic networks: Preferential
attachment or preferential acquisition? \emph{Psychological Science},
\emph{20}(6), 729--739.

\hypertarget{ref-jusczyk1994}{}
Jusczyk, P. W., Luce, P. A., \& Charles-Luce, J. (1994). Infant's
sensitivity to phonotactic patterns in the native language.
\emph{Journal of Memory and Language}, \emph{33}(5), 630--645.

\hypertarget{ref-higgins2014}{}
MacRoy-Higgins, M., Shafer, V. L., Schwartz, R. G., \& Marton, K.
(2014). The influence of phonotactic probability on word recognition in
toddlers. \emph{Child Language Teaching and Therapy}, \emph{30}(1),
117--130.

\hypertarget{ref-markman90}{}
Markman, E. M. (1990). Constraints children place on word meanings.
\emph{Cognitive Science}, \emph{14}(1), 57--77.

\hypertarget{ref-nelson1998}{}
Nelson, D. L., McEvoy, C. L., \& Schreiber, T. A. (1998). The University
of South Florida word association, rhyme, and word fragment norms.
Retrieved from \url{http://w3.usf.edu/FreeAssociation/}

\hypertarget{ref-roy2015}{}
Roy, B. C., Frank, M. C., DeCamp, P., Miller, M., \& Roy, D. (2015).
Predicting the birth of a spoken word. \emph{Proceedings of the National
Academy of Sciences}, \emph{112}(41), 12663--12668.
\url{http://doi.org/10.1073/pnas.1419773112}

\hypertarget{ref-smith2008}{}
Smith, L., \& Yu, C. (2008). Infants rapidly learn word-referent
mappings via cross-situational statistics. \emph{Cognition},
\emph{106}(3), 1558--1568.

\hypertarget{ref-stella2017}{}
Stella, M., Beckage, N. M., \& Brede, M. (2017). Multiplex lexical
networks reveal patterns in early word acquisition in children.
\emph{Scientific Reports}, \emph{7}.

\hypertarget{ref-steyvers2005}{}
Steyvers, M., \& Tenenbaum, J. B. (2005). The large-scale structure of
semantic networks: Statistical analyses and a model of semantic growth.
\emph{Cognitive Science}, \emph{29}(1), 41--78.

\hypertarget{ref-stokes2010}{}
Stokes, S. F. (2010). Neighborhood density and word frequency predict
vocabulary size in toddlers. \emph{Journal of Speech, Language, and
Hearing Research}, \emph{53}(3), 670--683.

\hypertarget{ref-storkel2001}{}
Storkel, H. L. (2001). Learning new words: Phonotactic probability in
language development. \emph{Journal of Speech, Language, and Hearing
Research}, \emph{44}(6), 1321--1337.

\hypertarget{ref-storkel2009}{}
Storkel, H. L. (2009). Developmental differences in the effects of
phonological, lexical and semantic variables on word learning by
infants. \emph{Journal of Child Language}, \emph{36}(2), 29--321.

\hypertarget{ref-vitevitch1999}{}
Vitevitch, M. S., Luce, P. A., Pisoni, D. B., \& Auer, E. T. (1999).
Phonotactics, neighborhood activation, and lexical access for spoken
words. \emph{Brain and Language}, \emph{68}(1), 306--311.

\end{document}
